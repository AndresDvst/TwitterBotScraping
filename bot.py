#!/usr/bin/env python3
"""
Bot de gestiÃ³n de usuarios de Twitter con CLI mejorado
"""

from manager import UsuariosManager
from scraper import TwitterScraper
from logger import bot_logger, log_exception
from config import Config
import sys


def mostrar_menu():
    """Muestra el menÃº principal"""
    print("\n" + "="*50)
    print("BOT DE GESTIÃ“N DE USUARIOS DE TWITTER")
    print("="*50)
    print("\n1. Modificar JSON de login (usuarios aleatorios)")
    print("2. Iniciar scraping automÃ¡tico (1 hora, cada 10 min)")
    print("3. Scraping manual (una sola pasada)")
    print("4. Ver estadÃ­sticas")
    print("5. Limpiar historial antiguo (>30 dÃ­as)")
    print("6. Salir")
    print("\n" + "="*50)


def obtener_usuarios_aleatorios():
    """OpciÃ³n 1: Obtener 10 usuarios"""
    try:
        manager = UsuariosManager()
        usuarios = manager.obtener_10_usuarios()
        
        print("\n" + "="*50)
        print("USUARIOS SELECCIONADOS:")
        print("="*50)
        
        if usuarios:
            for i, usuario in enumerate(usuarios, 1):
                print(f"{i}. @{usuario}")
        else:
            print("âš  No hay usuarios disponibles que no se hayan usado en los Ãºltimos 3 dÃ­as")
        
        print("="*50 + "\n")
        
    except Exception as e:
        log_exception(bot_logger, e, "Error obteniendo usuarios aleatorios")
        print(f"\nâœ— Error: {e}\n")


def modificar_json_login():
    """OpciÃ³n 1: Modificar login.json con 40 usuarios aleatorios"""
    try:
        manager = UsuariosManager()
        usuarios_fuente = manager.cargar_usuarios_base()
        
        manager.modificar_login_json(
            usuarios_fuente=usuarios_fuente,
            total_usuarios=40
        )
        
        print("\nâœ“ login.json actualizado con 40 usuarios aleatorios distribuidos en aurora/emily/eva/gaby")
        
    except Exception as e:
        log_exception(bot_logger, e, "Error modificando login.json")
        print(f"\nâœ— Error modificando login.json: {e}")


def iniciar_scraping_automatico():
    """OpciÃ³n 2: Scraping automÃ¡tico durante 1 hora"""
    print("\nâš  IMPORTANTE:")
    print("  - Debes estar LOGUEADO en Twitter en tu navegador")
    print("  - El bot abrirÃ¡ Chrome y navegarÃ¡ a tu feed")
    print("  - DurarÃ¡ 1 hora con pasadas cada 10 minutos")
    print("  - DarÃ¡ 10 likes por pasada para evitar detecciÃ³n ðŸ’™")
    
    confirmacion = input("\nÂ¿Continuar? (s/n): ").lower()
    
    if confirmacion != 's':
        print("OperaciÃ³n cancelada")
        return
    
    import time
    scraper = TwitterScraper(headless=False)
    
    try:
        bot_logger.info("Iniciando scraping automÃ¡tico...")
        scraper.iniciar_navegador()
        
        print("\nâ¸ PAUSA: El navegador estÃ¡ abierto.")
        print("Esperando 3 segundos antes de navegar a X...")
        time.sleep(3)
        
        # Navegar a X
        scraper.ir_a_twitter("https://x.com/home")
        
        print("\nâ¸ PAUSA: Por favor, LOGUEATE en Twitter/X manualmente si es necesario")
        print("Presiona ENTER cuando estÃ©s logueado y en tu feed...")
        input()
        
        # Iniciar scraping automÃ¡tico con likes
        scraper.mantener_sesion_activa(
            minutos=Config.DURACION_TOTAL_MINUTOS,
            intervalo_minutos=Config.INTERVALO_MINUTOS,
            usuarios_por_pasada=Config.USUARIOS_POR_PASADA,
            likes_por_pasada=Config.LIKES_POR_PASADA
        )
        
    except KeyboardInterrupt:
        bot_logger.warning("Proceso interrumpido por el usuario")
        print("\n\nâš  Proceso interrumpido por el usuario")
    except Exception as e:
        log_exception(bot_logger, e, "Error en scraping automÃ¡tico")
        print(f"\nâœ— Error: {e}")
    finally:
        scraper.cerrar()


def scraping_manual():
    """OpciÃ³n 3: Una sola pasada de scraping"""
    import time
    scraper = TwitterScraper(headless=False)
    manager = UsuariosManager()
    
    try:
        bot_logger.info("Iniciando scraping manual...")
        scraper.iniciar_navegador()
        
        print("\nâ¸ PAUSA: El navegador estÃ¡ abierto.")
        print("Esperando 3 segundos antes de navegar a X...")
        time.sleep(3)
        
        # Navegar a X
        scraper.ir_a_twitter("https://x.com/home")
        
        print("\nâ¸ PAUSA: Por favor, LOGUEATE en Twitter/X manualmente si es necesario")
        print("Presiona ENTER cuando estÃ©s listo...")
        input()
        
        # Hacer una pasada
        usuarios, likes_dados = scraper.scrapear_feed(
            scrolls=Config.SCROLL_COUNT,
            usuarios_objetivo=Config.USUARIOS_POR_PASADA,
            dar_likes_activo=True,
            likes_objetivo=Config.LIKES_POR_PASADA
        )
        
        # Agregar al manager
        agregados = manager.agregar_nuevos_usuarios(usuarios)
        
        print(f"\nðŸ“Š Resultados:")
        print(f"  - Usuarios encontrados: {len(usuarios)}")
        print(f"  - Usuarios nuevos: {len(agregados)}")
        print(f"  - Repetidos: {len(usuarios) - len(agregados)}")
        print(f"  - Likes dados: {likes_dados} ðŸ’™")
        
    except Exception as e:
        log_exception(bot_logger, e, "Error en scraping manual")
        print(f"\nâœ— Error: {e}")
    finally:
        scraper.cerrar()



def ver_estadisticas():
    """OpciÃ³n 4: Mostrar estadÃ­sticas"""
    try:
        manager = UsuariosManager()
        stats = manager.obtener_estadisticas()
        
        print("\n" + "="*50)
        print("ESTADÃSTICAS DEL SISTEMA")
        print("="*50)
        print(f"Total usuarios en base principal: {stats['total_principales']}")
        print(f"Total en historial (Ãºltimos 30 dÃ­as): {stats['total_historial']}")
        print(f"Total usuarios repetidos detectados: {stats['total_repetidos']}")
        print(f"Total en base inicial: {stats['total_base']}")
        print("="*50 + "\n")
        
    except Exception as e:
        log_exception(bot_logger, e, "Error obteniendo estadÃ­sticas")
        print(f"\nâœ— Error: {e}\n")


def limpiar_historial():
    """OpciÃ³n 5: Limpiar historial antiguo"""
    try:
        manager = UsuariosManager()
        eliminados = manager.limpiar_historial_antiguo()
        
        print(f"\nâœ“ Se eliminaron {eliminados} entradas del historial (>30 dÃ­as)")
        
    except Exception as e:
        log_exception(bot_logger, e, "Error limpiando historial")
        print(f"\nâœ— Error: {e}")


def main():
    """FunciÃ³n principal"""
    bot_logger.info("Bot iniciado")
    
    while True:
        mostrar_menu()
        
        try:
            opcion = input("Selecciona una opciÃ³n: ").strip()
            
            if opcion == '1':
                modificar_json_login()
            elif opcion == '2':
                iniciar_scraping_automatico()
            elif opcion == '3':
                scraping_manual()
            elif opcion == '4':
                ver_estadisticas()
            elif opcion == '5':
                limpiar_historial()
            elif opcion == '6':
                print("\nÂ¡Hasta luego! ðŸ‘‹\n")
                bot_logger.info("Bot finalizado por el usuario")
                sys.exit(0)
            else:
                print("\nâš  OpciÃ³n invÃ¡lida. Intenta de nuevo.")
                
        except KeyboardInterrupt:
            print("\n\nÂ¡Hasta luego! ðŸ‘‹\n")
            bot_logger.info("Bot interrumpido por el usuario")
            sys.exit(0)
        except Exception as e:
            log_exception(bot_logger, e, "Error inesperado en main loop")
            print(f"\nâœ— Error inesperado: {e}\n")


if __name__ == "__main__":
    main()

